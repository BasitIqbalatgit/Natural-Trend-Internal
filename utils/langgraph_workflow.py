import os
from typing import TypedDict, Annotated, List, Dict, Any
from langgraph.graph import StateGraph, END
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# Initialize OpenAI client directly
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def call_gpt4(system_message: str, user_message: str) -> str:
    """Helper function to call GPT-4"""
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error calling GPT-4: {str(e)}")
        return f"Error: {str(e)}"

class VettingState(TypedDict):
    """State for the vetting workflow"""
    company_name: str
    raw_data: Dict[str, Any]
    extracted_entities: Dict[str, Any]
    risk_analysis: Dict[str, Any]
    pg_questions_answered: Dict[str, str]
    final_report: Dict[str, Any]
    current_step: str

# P&G Vetting Questions
PG_VETTING_QUESTIONS = {
    "q1": "Does the company have a positive corporate reputation?",
    "q2": "Is the company free from current and serious public scandals?",
    "q3": "Is the company free from current and serious regulatory violations?",
    "q4": "Is the company free from current and serious legal violations?",
    "q5": "Are the company's principals/executives free from serious misconduct?",
    "q6": "Is there no negative media event likely to cause a PR 'black eye'?",
    "q7": "Does the company comply with brand safety standards?"
}

def extract_entities_node(state: VettingState) -> VettingState:
    """
    Extract key entities (executives, incidents, dates) from raw data
    """
    print("ðŸ” Extracting entities from raw data...")
    
    raw_data = state["raw_data"]
    
    # Prepare data for LLM analysis
    data_summary = f"""
    Company: {state['company_name']}
    
    General Search Results: {len(raw_data.get('comprehensive_search', {}).get('general_search', []))} results
    News Articles: {len(raw_data.get('comprehensive_search', {}).get('news_search', []))} articles
    Legal/Regulatory Info: {len(raw_data.get('comprehensive_search', {}).get('legal_regulatory', []))} items
    Recent News: {len(raw_data.get('recent_news', []))} recent articles
    Social Media: {sum(len(v) for v in raw_data.get('social_media', {}).values())} mentions
    """
    
    # Extract sample content for analysis
    all_content = []
    for result in raw_data.get('comprehensive_search', {}).get('general_search', [])[:5]:
        all_content.append(f"Title: {result.get('title', '')}\nContent: {result.get('content', '')}")
    
    for result in raw_data.get('comprehensive_search', {}).get('news_search', [])[:5]:
        all_content.append(f"News: {result.get('title', '')}\nContent: {result.get('content', '')}")
    
    content_text = "\n\n---\n\n".join(all_content[:10])  # Limit to prevent token overflow
    
    extraction_prompt = f"""
    Analyze the following information about {state['company_name']} and extract:
    
    1. Key executives and their roles
    2. Any incidents, scandals, or controversies mentioned
    3. Legal or regulatory issues
    4. Timeframes for any negative events
    5. Overall reputation indicators
    
    Data Summary:
    {data_summary}
    
    Sample Content:
    {content_text}
    
    Provide a structured JSON response with these categories.
    """
    
    try:
        response = call_gpt4(
            "You are an expert at entity extraction and corporate intelligence analysis.",
            extraction_prompt
        )
        
        state["extracted_entities"] = {
            "raw_analysis": response,
            "data_points": len(all_content),
            "processed": True
        }
    except Exception as e:
        print(f"Error in entity extraction: {str(e)}")
        state["extracted_entities"] = {"error": str(e), "processed": False}
    
    state["current_step"] = "entities_extracted"
    return state

def analyze_risks_node(state: VettingState) -> VettingState:
    """
    Analyze risks using GPT-4 with sophisticated prompting
    """
    print("âš ï¸  Analyzing risks with GPT-4...")
    
    raw_data = state["raw_data"]
    
    # Compile all negative indicators
    negative_content = []
    
    # News scandals
    for item in raw_data.get('comprehensive_search', {}).get('news_search', []):
        if any(keyword in item.get('content', '').lower() for keyword in 
               ['scandal', 'lawsuit', 'fraud', 'violation', 'controversy', 'investigation']):
            negative_content.append(f"NEWS: {item.get('title', '')} - {item.get('content', '')[:200]}")
    
    # Legal/regulatory
    for item in raw_data.get('comprehensive_search', {}).get('legal_regulatory', []):
        negative_content.append(f"LEGAL: {item.get('title', '')} - {item.get('content', '')[:200]}")
    
    negative_text = "\n\n".join(negative_content[:15])
    
    risk_analysis_prompt = f"""
    You are a corporate risk assessment expert for P&G brand safety compliance.
    
    Analyze the following information about {state['company_name']} and assess:
    
    1. SEVERITY: How serious are any negative findings? (Critical/High/Medium/Low/None)
    2. RECENCY: Are issues current (last 12 months) or historical?
    3. CREDIBILITY: Are sources credible and verified?
    4. PATTERN: Is there a pattern of misconduct or isolated incidents?
    5. IMPACT: Could this cause a PR "black eye" for P&G?
    
    Negative Indicators Found:
    {negative_text if negative_text else "No significant negative indicators found"}
    
    Provide a detailed risk assessment with specific evidence and reasoning.
    """
    
    try:
        response = call_gpt4(
            "You are an expert corporate risk analyst specializing in brand safety and reputation management.",
            risk_analysis_prompt
        )
        
        state["risk_analysis"] = {
            "analysis": response,
            "negative_items_found": len(negative_content),
            "processed": True
        }
    except Exception as e:
        print(f"Error in risk analysis: {str(e)}")
        state["risk_analysis"] = {"error": str(e), "processed": False}
    
    state["current_step"] = "risks_analyzed"
    return state

def answer_pg_questions_node(state: VettingState) -> VettingState:
    """
    Answer P&G's specific vetting questions using AI reasoning
    """
    print("ðŸ“‹ Answering P&G vetting questions...")
    
    risk_analysis = state["risk_analysis"].get("analysis", "No analysis available")
    
    questions_prompt = f"""
    Based on your risk analysis of {state['company_name']}, answer these P&G brand safety questions.
    
    For EACH question, provide:
    - Answer: YES / NO / MAYBE
    - Confidence: High / Medium / Low
    - Reasoning: 2-3 sentence explanation with specific evidence
    
    Risk Analysis Summary:
    {risk_analysis}
    
    Questions:
    1. Does the company have a positive corporate reputation?
    2. Is the company free from current and serious public scandals?
    3. Is the company free from current and serious regulatory violations?
    4. Is the company free from current and serious legal violations?
    5. Are the company's principals/executives free from serious misconduct?
    6. Is there no negative media event likely to cause a PR 'black eye'?
    7. Does the company comply with brand safety standards?
    
    Provide structured answers in JSON format.
    """
    
    try:
        response = call_gpt4(
            "You are a P&G brand safety compliance officer making critical vetting decisions.",
            questions_prompt
        )
        
        state["pg_questions_answered"] = {
            "answers": response,
            "processed": True
        }
    except Exception as e:
        print(f"Error answering P&G questions: {str(e)}")
        state["pg_questions_answered"] = {"error": str(e), "processed": False}
    
    state["current_step"] = "questions_answered"
    return state

def generate_report_node(state: VettingState) -> VettingState:
    """
    Generate final comprehensive report
    """
    print("ðŸ“„ Generating final report...")
    
    report_prompt = f"""
    Create a comprehensive executive summary for {state['company_name']} vetting report.
    
    Include:
    1. Overall Recommendation (APPROVED / REJECTED / REQUIRES REVIEW)
    2. Key Findings (3-5 bullet points)
    3. Risk Level (Low / Medium / High / Critical)
    4. Action Items (if any)
    
    Based on:
    - Risk Analysis: {state['risk_analysis'].get('analysis', 'N/A')[:500]}
    - P&G Questions: {state['pg_questions_answered'].get('answers', 'N/A')[:500]}
    
    Be concise, professional, and actionable.
    """
    
    try:
        response = call_gpt4(
            "You are a senior compliance officer creating executive-level reports.",
            report_prompt
        )
        
        state["final_report"] = {
            "executive_summary": response,
            "company_name": state["company_name"],
            "data_sources_checked": sum([
                len(state["raw_data"].get('comprehensive_search', {}).get('general_search', [])),
                len(state["raw_data"].get('comprehensive_search', {}).get('news_search', [])),
                len(state["raw_data"].get('recent_news', [])),
            ]),
            "processed": True
        }
    except Exception as e:
        print(f"Error generating report: {str(e)}")
        state["final_report"] = {"error": str(e), "processed": False}
    
    state["current_step"] = "report_generated"
    return state

def create_vetting_workflow() -> StateGraph:
    """
    Create the LangGraph workflow for company vetting
    """
    workflow = StateGraph(VettingState)
    
    # Add nodes
    workflow.add_node("extract_entities", extract_entities_node)
    workflow.add_node("analyze_risks", analyze_risks_node)
    workflow.add_node("answer_questions", answer_pg_questions_node)
    workflow.add_node("generate_report", generate_report_node)
    
    # Define edges (workflow flow)
    workflow.set_entry_point("extract_entities")
    workflow.add_edge("extract_entities", "analyze_risks")
    workflow.add_edge("analyze_risks", "answer_questions")
    workflow.add_edge("answer_questions", "generate_report")
    workflow.add_edge("generate_report", END)
    
    return workflow.compile()

def run_vetting_analysis(company_name: str, raw_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Execute the complete vetting workflow
    """
    print(f"\n{'='*60}")
    print(f"ðŸš€ Starting AI-Powered Vetting for: {company_name}")
    print(f"{'='*60}\n")
    
    # Validate OpenAI API key
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError("OPENAI_API_KEY not found in environment variables")
    
    # Check if sufficient data exists
    total_results = raw_data.get('total_results', 0)
    data_found = raw_data.get('data_found', False)
    
    if not data_found or total_results < 3:
        print(f"âš ï¸ WARNING: Limited data available ({total_results} results). Analysis may be incomplete.")
        # Create a limited report for companies with no data
        return VettingState(
            company_name=company_name,
            raw_data=raw_data,
            extracted_entities={"note": "Insufficient data for entity extraction"},
            risk_analysis={
                "analysis": f"**INSUFFICIENT DATA WARNING**: Only {total_results} data points found for '{company_name}'. "
                           f"This company may not exist, may be too small/private, or the name may be incorrect. "
                           f"**Recommendation**: REQUIRES MANUAL REVIEW - Verify company existence and spelling before proceeding.",
                "negative_items_found": 0,
                "processed": True
            },
            pg_questions_answered={
                "answers": "**INSUFFICIENT DATA**: Unable to answer P&G questions due to lack of information. Manual vetting required.",
                "processed": False
            },
            final_report={
                "executive_summary": f"## âš ï¸ INSUFFICIENT DATA FOR: {company_name}\n\n"
                                   f"**Status**: REQUIRES MANUAL REVIEW\n\n"
                                   f"**Reason**: Only {total_results} data points found during search.\n\n"
                                   f"**Possible Causes**:\n"
                                   f"- Company name misspelled or incorrect\n"
                                   f"- Company does not exist or is not publicly known\n"
                                   f"- Company is too small/private for public data\n"
                                   f"- Company operates under a different legal name\n\n"
                                   f"**Recommended Action**: Verify company information manually before proceeding with vetting.",
                "company_name": company_name,
                "data_sources_checked": total_results,
                "processed": True
            },
            current_step="insufficient_data"
        )
    
    # Initialize state
    initial_state = VettingState(
        company_name=company_name,
        raw_data=raw_data,
        extracted_entities={},
        risk_analysis={},
        pg_questions_answered={},
        final_report={},
        current_step="initialized"
    )
    
    # Create and run workflow
    workflow = create_vetting_workflow()
    
    try:
        final_state = workflow.invoke(initial_state)
        print(f"\n{'='*60}")
        print("âœ… Vetting Analysis Complete!")
        print(f"{'='*60}\n")
        return final_state
    except Exception as e:
        print(f"âŒ Error in workflow execution: {str(e)}")
        # Return error state
        initial_state["final_report"] = {
            "executive_summary": f"## âŒ ERROR DURING ANALYSIS\n\n**Error**: {str(e)}\n\n**Recommendation**: Check API keys and try again.",
            "company_name": company_name,
            "data_sources_checked": 0,
            "processed": False,
            "error": str(e)
        }
        initial_state["current_step"] = "error"
        return initial_state
